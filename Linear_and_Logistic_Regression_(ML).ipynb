{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPxkGbdTkgDne6YGYIqVuiT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/00abhinav-u/Machine-Learning-assignment/blob/main/Linear_and_Logistic_Regression_(ML).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WZzfnqOAmzG"
      },
      "outputs": [],
      "source": [
        "def multiply_lists(w, x):\n",
        "    result = 0\n",
        "    for i in range(len(w)):\n",
        "        result += w[i] * x[i]\n",
        "    return result\n",
        "\n",
        "class LinearRegression:\n",
        "    def __init__(self):\n",
        "        self.learning_rate = 0.01\n",
        "        self.iterations = 5000\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples = len(X)\n",
        "        n_features = len(X[0])\n",
        "        self.weights = [0.01 for _ in range(n_features)]\n",
        "        self.bias = 0.0\n",
        "\n",
        "        for _ in range(self.iterations):\n",
        "            y_pred = []\n",
        "            for x in X:\n",
        "                pred = multiply_lists(self.weights, x) + self.bias\n",
        "                y_pred.append(pred)\n",
        "\n",
        "            dw = [0.0] * n_features\n",
        "            db = 0.0\n",
        "            for i in range(n_samples):\n",
        "                error = y_pred[i] - y[i]\n",
        "                for j in range(n_features):\n",
        "                    dw[j] += error * X[i][j]\n",
        "                db += error\n",
        "\n",
        "            dw = [d / n_samples for d in dw]\n",
        "            db = db / n_samples\n",
        "\n",
        "            for j in range(n_features):\n",
        "                self.weights[j] -= self.learning_rate * dw[j]\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            pred = multiply_lists(self.weights, x) + self.bias\n",
        "            predictions.append(pred)\n",
        "        return predictions\n",
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self):\n",
        "        self.learning_rate = 0.1\n",
        "        self.iterations = 5000\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        if z > 10:\n",
        "            return 1.0\n",
        "        if z < -10:\n",
        "            return 0.0\n",
        "        return 1.0 / (1.0 + 2.718 ** (-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples = len(X)\n",
        "        n_features = len(X[0])\n",
        "        self.weights = [0.01 for _ in range(n_features)]\n",
        "        self.bias = 0.0\n",
        "\n",
        "        for _ in range(self.iterations):\n",
        "            y_pred = []\n",
        "            for x in X:\n",
        "                z = multiply_lists(self.weights, x) + self.bias\n",
        "                prob = self.sigmoid(z)\n",
        "                y_pred.append(prob)\n",
        "\n",
        "            dw = [0.0] * n_features\n",
        "            db = 0.0\n",
        "            for i in range(n_samples):\n",
        "                error = y_pred[i] - y[i]\n",
        "                for j in range(n_features):\n",
        "                    dw[j] += error * X[i][j]\n",
        "                db += error\n",
        "\n",
        "            dw = [d / n_samples for d in dw]\n",
        "            db = db / n_samples\n",
        "\n",
        "            for j in range(n_features):\n",
        "                self.weights[j] -= self.learning_rate * dw[j]\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            z = multiply_lists(self.weights, x) + self.bias\n",
        "            prob = self.sigmoid(z)\n",
        "            pred = 1 if prob >= 0.5 else 0\n",
        "            predictions.append(pred)\n",
        "        return predictions\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X_linear = [[1.0], [2.0], [3.0], [4.0]]\n",
        "    y_linear = [2.0, 4.0, 6.0, 8.0]\n",
        "\n",
        "    lin_reg = LinearRegression()\n",
        "    lin_reg.fit(X_linear, y_linear)\n",
        "    print(\"Linear Predictions:\", lin_reg.predict(X_linear))\n",
        "\n",
        "    X_logistic = [[1.0], [2.0], [3.0], [4.0]]\n",
        "    y_logistic = [0, 0, 1, 1]\n",
        "\n",
        "    log_reg = LogisticRegression()\n",
        "    log_reg.fit(X_logistic, y_logistic)\n",
        "    print(\"Logistic Predictions:\", log_reg.predict(X_logistic))"
      ]
    }
  ]
}